{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show code for estimating the multinomial mixture algorithm using the EM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import topicmodels  # pip install topic-modelling-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the illustration, we use text data from US State-of-the-Union addreses accessed from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>speech</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Rep...</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington</td>\n",
       "      <td>I embrace with great satisfaction the opportun...</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Washington</td>\n",
       "      <td>In resuming your consultations for the general...</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Among the many interesting objects which will ...</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington</td>\n",
       "      <td>A free people ought not only to be armed, but ...</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    president                                             speech  year\n",
       "0  Washington  Fellow-Citizens of the Senate and House of Rep...  1790\n",
       "1  Washington  I embrace with great satisfaction the opportun...  1790\n",
       "2  Washington  In resuming your consultations for the general...  1790\n",
       "3  Washington  Among the many interesting objects which will ...  1790\n",
       "4  Washington  A free people ought not only to be armed, but ...  1790"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://github.com/sekhansen/text-mining-tutorial/raw/master/speech_data_extend.txt\"\n",
    "df = pd.read_table(url, encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only keep data from the year 2000 to speed computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>speech</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21923</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21924</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>We are fortunate to be alive at this moment in...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21925</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>We begin the new century with over 20 million ...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21926</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>And our economic revolution has been matched b...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21927</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>My fellow Americans, the state of our Union is...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      president                                             speech  year\n",
       "21923   Clinton  Mr. Speaker, Mr. Vice President, Members of Co...  2000\n",
       "21924   Clinton  We are fortunate to be alive at this moment in...  2000\n",
       "21925   Clinton  We begin the new century with over 20 million ...  2000\n",
       "21926   Clinton  And our economic revolution has been matched b...  2000\n",
       "21927   Clinton  My fellow Americans, the state of our Union is...  2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.year >= 2000]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,232 paragraphs in the data.  Here we define a document as a paragraph of a State-of-the-Union speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the standard pre-processing steps discussed in the information retrieval notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsobj = topicmodels.RawDocs(df.speech.values, \"long\")\n",
    "docsobj.token_clean(1)\n",
    "docsobj.stopword_remove(\"tokens\")\n",
    "docsobj.stem()\n",
    "docsobj.stopword_remove(\"stems\")\n",
    "docsobj.term_rank(\"stems\")\n",
    "docsobj.rank_remove(\"tfidf\", \"stems\", docsobj.tfidf_ranking[2300][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we form the bag-of-words for the data, and store the mapping from term indices to terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2119\n",
      "risk\n"
     ]
    }
   ],
   "source": [
    "bowobj = topicmodels.BOW(docsobj.stems)\n",
    "V = bowobj.bow.shape[1] # dimensionality of document-term matrix\n",
    "print(V)\n",
    "inv_map = {v: k for k, v in bowobj.token_key.items()}\n",
    "print(inv_map[10]) # illustrative token (here the 11th token in the vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we estimate the multinomial mixture model with $K=2$ starting from $5$ different random initial values for the parameters, and store the estimated model with the high log-likelihood achieved after convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence at iteration 58, loglik = -259978.232300\n",
      "Iteration 1\n",
      "convergence at iteration 28, loglik = -260263.978654\n",
      "Iteration 2\n",
      "convergence at iteration 53, loglik = -260438.082410\n",
      "Iteration 3\n",
      "convergence at iteration 111, loglik = -260910.504415\n",
      "Iteration 4\n",
      "convergence at iteration 408, loglik = -261505.333250\n",
      "Iteration 5\n"
     ]
    }
   ],
   "source": [
    "K=2\n",
    "\n",
    "emobjs = []\n",
    "loglik = []\n",
    "\n",
    "for i in range(5):\n",
    "    emobj = topicmodels.multimix.EM(bowobj.bow, K) # pass the document-term matrix and K=2\n",
    "    emobj.estimate(1000) # 1000 is maximum number of iterations\n",
    "    loglik.append(emobj.loglik[-1])\n",
    "    emobjs.append(emobj)\n",
    "    print(\"Iteration\", i+1)\n",
    "\n",
    "em_best = emobjs[np.argmax(loglik)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can observe the log-likelihood of the best-fit model at each iteration.  Recall the EM algorithm will increase the value of the log-likelihood at each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-312800.41304647, -264775.6371536 , -263275.08287791,\n",
       "       -261468.31962337, -260612.50709653, -260329.35055897,\n",
       "       -260180.46226923, -260089.36617841, -260054.63660178,\n",
       "       -260033.83929252, -260011.142693  , -260002.38501813,\n",
       "       -260000.28186984, -259993.52707618, -259992.10603947,\n",
       "       -259991.9089792 , -259991.5272684 , -259991.25509288,\n",
       "       -259990.96147203, -259989.21364744, -259987.27901749,\n",
       "       -259987.18365775, -259987.13416613, -259987.1110509 ,\n",
       "       -259987.10213481, -259987.09899946, -259987.09793535,\n",
       "       -259987.09757854, -259987.09745933, -259987.09741948,\n",
       "       -259987.09740591, -259987.09740029, -259987.09739406,\n",
       "       -259987.09737457, -259987.09729854, -259987.09699514,\n",
       "       -259987.09577518, -259987.0907563 , -259987.06816972,\n",
       "       -259986.92567825, -259985.12238309, -259978.68856164,\n",
       "       -259978.25400745, -259978.24092477, -259978.23592499,\n",
       "       -259978.23386481, -259978.23298532, -259978.23260274,\n",
       "       -259978.23243447, -259978.23235996, -259978.23232682,\n",
       "       -259978.23231203, -259978.23230542, -259978.23230246,\n",
       "       -259978.23230113, -259978.23230054, -259978.23230027,\n",
       "       -259978.23230015, -259978.23230009])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_best.loglik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are interested in the estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58107194, 0.41892806])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_best.rho # the estimated mixing probabilities over the two topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the estimated mixing probabilities, the model estimates the probability that each term appears in each of the topics.  We construct a matrix that orders terms based on their probability in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.zeros((K, V), dtype=np.int)\n",
    "for k in range(K):\n",
    "    indices[k, :] = em_best.mu[k, :].argsort()\n",
    "\n",
    "top = [[] for k in range(K)]\n",
    "\n",
    "for i in range(-1, -20, -1):\n",
    "    for k in range(K):\n",
    "        top[k].append(inv_map[indices[k][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'job', u'help', u'tax', u'need', u'busi', u'must', u'health', u'economi', u'congress', u'care', u'energi', u'school', u'ask', u'time', u'million', u'let', u'tonight', u'reform', u'children']\n"
     ]
    }
   ],
   "source": [
    "print(top[0]) # top terms in topic0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'world', u'countri', u'must', u'terrorist', u'iraq', u'state', u'secur', u'freedom', u'govern', u'unit', u'time', u'come', u'war', u'weapon', u'iraqi', u'peac', u'tonight', u'know', u'support']\n"
     ]
    }
   ],
   "source": [
    "print(top[1]) # top terms in topic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it appears the model has uncovered an interpretable latent space with a \"domestic policy\" dimension and a \"foreign policy\" dimension."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
